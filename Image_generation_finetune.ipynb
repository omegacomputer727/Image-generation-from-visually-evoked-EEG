{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2d2c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:34:47.831731Z",
     "iopub.status.busy": "2024-05-07T12:34:47.830836Z",
     "iopub.status.idle": "2024-05-07T12:35:19.222101Z",
     "shell.execute_reply": "2024-05-07T12:35:19.221016Z"
    },
    "papermill": {
     "duration": 31.401338,
     "end_time": "2024-05-07T12:35:19.224664",
     "exception": false,
     "start_time": "2024-05-07T12:34:47.823326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e005fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "#data already prepared before using in this notebook\n",
    "dir = 'path to main directory'\n",
    "data_train = torch.load(os.path.join(dir, 'eeg train dataset file'))\n",
    "data_test = torch.load(os.path.join(dir, 'eeg test dataset file'))\n",
    "ds_train = data_train['dataset']\n",
    "ds_test = data_test['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5950934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:35:19.261028Z",
     "iopub.status.busy": "2024-05-07T12:35:19.260681Z",
     "iopub.status.idle": "2024-05-07T12:35:22.305645Z",
     "shell.execute_reply": "2024-05-07T12:35:22.304726Z"
    },
    "papermill": {
     "duration": 3.057807,
     "end_time": "2024-05-07T12:35:22.311776",
     "exception": false,
     "start_time": "2024-05-07T12:35:19.253969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load bilstm encoder model\n",
    "bilstmencoder = load_model('path to encoder model file')\n",
    "bilstmencoder = Model(inputs=bilstmencoder.inputs, outputs=bilstmencoder.layers[-2].output)\n",
    "bilstmencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062535b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:35:22.328956Z",
     "iopub.status.busy": "2024-05-07T12:35:22.328397Z",
     "iopub.status.idle": "2024-05-07T12:36:49.276321Z",
     "shell.execute_reply": "2024-05-07T12:36:49.275456Z"
    },
    "papermill": {
     "duration": 86.959064,
     "end_time": "2024-05-07T12:36:49.278747",
     "exception": false,
     "start_time": "2024-05-07T12:35:22.319683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprocessing steps\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "\n",
    "def preprocess_X(X, ds)->None:\n",
    "    for i in ds:\n",
    "        X.append(i['eeg'].numpy())\n",
    "\n",
    "preprocess_X(X_train, ds_train)\n",
    "preprocess_X(X_test, ds_test)\n",
    "\n",
    "def trim(X, max_cols)->None:\n",
    "    X_trimmed = [arr[:, :max_cols] for arr in X if arr.shape[1] >= max_cols]\n",
    "    return np.array(X_trimmed)\n",
    "\n",
    "X_train = trim(X_train, 480)\n",
    "X_test = trim(X_test, 480)\n",
    "    \n",
    "image_ids_train = ds_train['images']\n",
    "image_ids_test = ds_test['images']\n",
    "\n",
    "def resize_image(image, target_size=(64, 64)):\n",
    "    return cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), target_size)\n",
    "\n",
    "for i in ds_train['dataset']:\n",
    "    Y_train.append(np.array(resize_image(cv2.imread('path to dir with images that are part of the eeg-image pairs dataset'+image_ids_train[i['image']]+'.JPEG')))/255)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "for i in ds_test['dataset']:\n",
    "    Y_test.append(np.array(resize_image(cv2.imread('path to dir with images that are part of the eeg-image pairs dataset'+image_ids_test[i['image']]+'.JPEG')))/255)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b8d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:36:52.240210Z",
     "iopub.status.busy": "2024-05-07T12:36:52.239965Z",
     "iopub.status.idle": "2024-05-07T12:36:53.261583Z",
     "shell.execute_reply": "2024-05-07T12:36:53.260733Z"
    },
    "papermill": {
     "duration": 1.043189,
     "end_time": "2024-05-07T12:36:53.263908",
     "exception": false,
     "start_time": "2024-05-07T12:36:52.220719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the pretrained vae\n",
    "\n",
    "input_shape = (64, 64, 3) \n",
    "encoder_input = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(64, 3, strides=1, activation = 'relu', padding = 'same')(encoder_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, 5, strides=2, activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, 3, strides=1, activation = 'relu')(x)\n",
    "x = Conv2D(128, 5, strides=1, activation = 'relu')(x)\n",
    "x = Conv2D(256, 3, strides=1, activation = 'relu')(x)\n",
    "x = Conv2D(512, 3, strides=2, activation = 'relu')(x)\n",
    "x = Conv2D(64, 3, strides=2, activation = 'relu', padding = 'same')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "latent_dim = 2*2*64\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(encoder_input, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='latent_inputs')\n",
    "x = Reshape((2, 2, 64))(latent_inputs)\n",
    "x = Conv2DTranspose(512, 3, strides=2, activation='relu')(x)\n",
    "x = Conv2DTranspose(256, 5, strides=1, activation='relu')(x)\n",
    "x = Conv2DTranspose(256, 3, strides=1, activation='relu')(x)\n",
    "x = Conv2DTranspose(256, 5, strides=1, activation='relu', padding = 'same')(x)\n",
    "x = Conv2DTranspose(128, 3, strides=1, activation='relu')(x)\n",
    "x = Conv2DTranspose(128, 4, strides=1, activation='relu')(x)\n",
    "x = UpSampling2D()(x)\n",
    "x = Conv2DTranspose(64, 3, strides=2, padding = 'same', activation='relu')(x)\n",
    "decoder_output = Conv2DTranspose(3, 3, strides=1,padding = 'same', activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, decoder_output, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "vae_outputs = decoder(encoder(encoder_input)[2])\n",
    "vae = Model(encoder_input, vae_outputs, name='vae')\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = K.mean(K.square(y_true - y_pred))\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    kl_loss = K.mean(kl_loss)\n",
    "    return (loss1) + (kl_loss)\n",
    "\n",
    "vae.compile(optimizer='adam', loss = custom_loss)\n",
    "vae.summary()\n",
    "vae.load_weights('path to vae weigths')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2338b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:36:53.316422Z",
     "iopub.status.busy": "2024-05-07T12:36:53.315685Z",
     "iopub.status.idle": "2024-05-07T12:36:54.898240Z",
     "shell.execute_reply": "2024-05-07T12:36:54.897479Z"
    },
    "papermill": {
     "duration": 1.610493,
     "end_time": "2024-05-07T12:36:54.900230",
     "exception": false,
     "start_time": "2024-05-07T12:36:53.289737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add dense layer to encoder and pretrained vae decoder to create combined model\n",
    "\n",
    "decoder_input = vae.get_layer('decoder').input \n",
    "decoder_output = vae.get_layer('decoder').output \n",
    "\n",
    "decoder_model = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
    "# for layer in decoder_model.layers:\n",
    "#     layer.trainable = True\n",
    "decoder_model.summary()\n",
    "\n",
    "bilstmencoder_input = bilstmencoder.input\n",
    "bilstmencoder_output = bilstmencoder.output\n",
    "x = Dense(256, activation='relu', name = 'hehe')(bilstmencoder_output)\n",
    "\n",
    "modified_bilstmencoder = Model(inputs=bilstmencoder_input, outputs=x)\n",
    "\n",
    "for layer in modified_bilstmencoder.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "combined_model = Sequential([modified_bilstmencoder, decoder_model])\n",
    "combined_model.summary()\n",
    "combined_model.compile(optimizer='adam', loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab250001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:36:55.090982Z",
     "iopub.status.busy": "2024-05-07T12:36:55.090342Z",
     "iopub.status.idle": "2024-05-07T12:49:38.286282Z",
     "shell.execute_reply": "2024-05-07T12:49:38.285253Z"
    },
    "papermill": {
     "duration": 763.249298,
     "end_time": "2024-05-07T12:49:38.308841",
     "exception": false,
     "start_time": "2024-05-07T12:36:55.059543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#training loop\n",
    "history = combined_model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs = 100, \n",
    "    validation_split = 0.05,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51fabc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:49:39.881540Z",
     "iopub.status.busy": "2024-05-07T12:49:39.880676Z",
     "iopub.status.idle": "2024-05-07T12:49:40.096222Z",
     "shell.execute_reply": "2024-05-07T12:49:40.095264Z"
    },
    "papermill": {
     "duration": 0.956721,
     "end_time": "2024-05-07T12:49:40.098538",
     "exception": false,
     "start_time": "2024-05-07T12:49:39.141817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loss curves\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa3ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:49:41.630967Z",
     "iopub.status.busy": "2024-05-07T12:49:41.630233Z",
     "iopub.status.idle": "2024-05-07T12:49:42.319728Z",
     "shell.execute_reply": "2024-05-07T12:49:42.318753Z"
    },
    "papermill": {
     "duration": 1.475954,
     "end_time": "2024-05-07T12:49:42.322022",
     "exception": false,
     "start_time": "2024-05-07T12:49:40.846068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load test images to visualize ground truths\n",
    "Y_visualize = []\n",
    "for i in ds_test['dataset']:\n",
    "    m = cv2.imread('path to dir with images that are part of the eeg-image pairs dataset'+image_ids_test[i['image']]+'.JPEG')\n",
    "    m = cv2.cvtColor(m, cv2.COLOR_BGR2RGB)\n",
    "    Y_visualize.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c54ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:49:43.852795Z",
     "iopub.status.busy": "2024-05-07T12:49:43.852413Z",
     "iopub.status.idle": "2024-05-07T12:50:06.364441Z",
     "shell.execute_reply": "2024-05-07T12:50:06.363105Z"
    },
    "papermill": {
     "duration": 23.347619,
     "end_time": "2024-05-07T12:50:06.406629",
     "exception": false,
     "start_time": "2024-05-07T12:49:43.059010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show generated images\n",
    "generated_images = combined_model.predict(X_test)\n",
    "num_images_to_display = 50  \n",
    "\n",
    "plt.figure(figsize=(6, 2*num_images_to_display))  \n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    plt.subplot(num_images_to_display, 2, 2*i + 1)  \n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    plt.subplot(num_images_to_display, 2, 2*i + 2)  \n",
    "    plt.imshow(Y_visualize[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4525556,
     "sourceId": 7742480,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4101327,
     "sourceId": 8012227,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 967.978259,
   "end_time": "2024-05-07T12:50:39.735302",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-07T12:34:31.757043",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
